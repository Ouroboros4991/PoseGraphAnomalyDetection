{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0066d2cb-2afe-45d2-b3f4-7e4ce476d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import convert\n",
    "import networkx as nx \n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from ast import literal_eval\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c0960d-b75b-4861-b2c1-eb816d1c0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources\n",
    "# https://medium.com/cj-express-tech-tildi/first-timers-guide-to-pytorch-geometric-part-1-the-basic-1b6006e1f4db\n",
    "\n",
    "# Ground truth UB normal:\n",
    "# 1 is normal\n",
    "# 0 is abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d05014-a079-45dc-8ff5-ccfb209da9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2e2b7-32d6-472f-ae66-996a0d96ec07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3090c00-4379-4477-ad30-9df88c0940f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b1640a1-14b5-4db9-98c0-44d62461a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jsons(directory: str):\n",
    "    \"\"\"Function that exctracts the mp4 files from the given directory\n",
    "    and returns the path to the video and it's annotations.\n",
    "    \"\"\"\n",
    "    filelist = [];\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                json_file = os.path.join(root,file)\n",
    "                filelist.append(json_file)\n",
    "    return filelist\n",
    "\n",
    "\n",
    "def normalize_keypoints(keypoints):\n",
    "    # Transform 1: Set Nose as origin\n",
    "    nose_index = order.index('Nose')\n",
    "    nose_co, _ = keypoints[nose_index]\n",
    "    tmp_keypoints = []\n",
    "    for kp in keypoints:\n",
    "        co, confidence = kp\n",
    "        adj_x = co[0] - nose_co[0]\n",
    "        adj_y = co[1] - nose_co[1]\n",
    "        adj_co = (adj_x, adj_y)\n",
    "        tmp_keypoints.append((adj_co, confidence))\n",
    "    # Transofmr 2: Standardize pose size.\n",
    "    # This is done by setting the distance between the shoulders to 1\n",
    "    rshoulder_index = order.index('RShoulder')\n",
    "    lshoulder_index = order.index('LShoulder')\n",
    "    co1 = keypoints[rshoulder_index][0]\n",
    "    co2 = keypoints[lshoulder_index][0]\n",
    "    distance = math.dist(co1, co2)\n",
    "    normalized_keypoints = []\n",
    "    for kp in tmp_keypoints:\n",
    "        co, confidence = kp\n",
    "        adj_x = co[0]/distance\n",
    "        adj_y = co[1]/distance\n",
    "        adj_co = (adj_x, adj_y)\n",
    "        normalized_keypoints.append((adj_co, confidence))\n",
    "    return normalized_keypoints\n",
    "\n",
    "\n",
    "def reformat_kp(key_points):\n",
    "    \"\"\"Reformat the keypoints so that the array\n",
    "    contains 1 item per keypoints.\n",
    "    Each item should have the following format containing\n",
    "    the coordinates the first element and the confidence as the\n",
    "    second element:\n",
    "    Tuple[Tuple[float, float], float]\n",
    "    \"\"\"\n",
    "    co_keypoints = []\n",
    "    for i in range(0, len(key_points), 3):\n",
    "        x = float(key_points[i])\n",
    "        y = float(key_points[i+1])\n",
    "        c = float(key_points[i+2])\n",
    "        co = (x,y)\n",
    "        co_keypoints.append((co, c))\n",
    "    return co_keypoints\n",
    "\n",
    "def load_tracking_jsons(json_files):\n",
    "    \"\"\"\n",
    "    Load in the jsons with the corresponding ground truth\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for file in json_files:\n",
    "        if file.endswith('tracked_person.json'):\n",
    "            video = '_'.join(file.split('/')[-1].split('-')[0].split('_')[0:-1])\n",
    "            with open(file) as f:\n",
    "                tracking = json.load(f)\n",
    "             # The ground truth shared in the repo of STG-NF contains two formats\n",
    "            # One is a Numpy array, the other is a text file containing per person if which frame contains invalid poses\n",
    "            # As we want to focus on detecting abnormallies in the pose graph,\n",
    "            # we only want to have the videos with a grond truth on person basis.\n",
    "            gt_file = f'./data/UBnormal/annotations/{video.replace(\"alphapose_tracked\", \"tracks\")}.txt'\n",
    "            try:\n",
    "                np.load(gt_file)\n",
    "                continue\n",
    "            # If there is no ground truth, ignore the video\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            except ValueError:\n",
    "                with open(gt_file) as file:\n",
    "                    lines = [line.strip() for line in file]\n",
    "                gt_video = {}\n",
    "                for gt in lines:\n",
    "                    person, start_frame, end_frame = gt.split(',')\n",
    "                    # Use float to deal with scientific notation\n",
    "                    person = int(float(person))\n",
    "                    start_frame = int(float(start_frame))\n",
    "                    end_frame = int(float(end_frame))\n",
    "                    gt_video[person] = (start_frame, end_frame)\n",
    "            items = []\n",
    "            for person, tracking_data in tracking.items():\n",
    "                # If it's not in the gt dict, it means that the person has a normal pose\n",
    "                # for the whole video aka there is no frame in which the person has an abnormal frame\n",
    "                start_frame, end_frame = gt_video.get(int(person), (-1, -1)) \n",
    "                for frame, data in tracking_data.items():\n",
    "                    frame_number = int(frame)\n",
    "                    data['frame'] = frame_number\n",
    "                    if start_frame <= frame_number <= end_frame:\n",
    "                        data['label'] = 'abnormal'\n",
    "                    else:\n",
    "                        data['label'] = 'normal'\n",
    "                    items.append(data)\n",
    "            if items:\n",
    "                df = pd.DataFrame(items)\n",
    "                df['video'] = video\n",
    "                df = df[['video', 'frame', 'label', 'keypoints', 'scores']]\n",
    "                dfs.append(df)\n",
    "    df_overview = pd.concat(dfs, ignore_index=True)\n",
    "    return df_overview\n",
    "\n",
    "\n",
    "def get_edge_weight(graph):\n",
    "    edges = nx.get_edge_attributes(graph, 'weight')\n",
    "    edge_weights = []\n",
    "    # Ensure order of list is the same\n",
    "    for source, target in connections:\n",
    "        n1 = order[source]\n",
    "        n2 = order[target]\n",
    "        try:\n",
    "            weight = edges[(n1, n2)]\n",
    "        # as the direction doesn't matter in this graph, it's possible that the keys are stored in a different order \n",
    "        # in the graph\n",
    "        except KeyError:\n",
    "            weight = edges[(n2, n1)]\n",
    "        edge_weights.append(weight)\n",
    "    return edge_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927e1814-10ef-4f12-a976-d649f80922ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provided_poses = load_tracking_jsons(get_jsons('./data/UBnormal/poses'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb99b89-47df-4e9f-b8fe-62abde4dcbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71527e18-fa0d-4a24-a0c0-1d83caac5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_provided_poses.sample(frac=0.80)\n",
    "df_subset =  df_provided_poses.drop(df_training.index)\n",
    "df_validation = df_subset.sample(frac=0.5)\n",
    "df_test = df_subset.drop(df_validation.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0642750-b811-4b9c-a499-3e7245b8388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('./PyGod/data/UBnormal/training.csv', index=False)\n",
    "df_validation.to_csv('./PyGod/data/UBnormal/validation.csv', index=False)\n",
    "df_test.to_csv('./PyGod/data/UBnormal/testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e55ae44-e032-446d-9afd-9b87de3f5ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22929, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c73b3b-c710-496f-b269-aad7a7320341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70d1090e-4f38-4661-a698-fcb91ac1f8fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Labels of the keypoints in order\n",
    "# Source https://github.com/MVIG-SJTU/AlphaPose/blob/master/docs/output.md\n",
    "raw_order = [\n",
    "    {0,  \"Nose\"},\n",
    "    {1,  \"LEye\"},\n",
    "    {2,  \"REye\"},\n",
    "    {3,  \"LEar\"},\n",
    "    {4,  \"REar\"},\n",
    "    {5,  \"LShoulder\"},\n",
    "    {6,  \"RShoulder\"},\n",
    "    {7,  \"LElbow\"},\n",
    "    {8,  \"RElbow\"},\n",
    "    {9,  \"LWrist\"},\n",
    "    {10, \"RWrist\"},\n",
    "    {11, \"LHip\"},\n",
    "    {12, \"RHip\"},\n",
    "    {13, \"LKnee\"},\n",
    "    {14, \"Rknee\"},\n",
    "    {15, \"LAnkle\"},\n",
    "    {16, \"RAnkle\"},\n",
    "]\n",
    "order = []\n",
    "for s in raw_order:\n",
    "    for item in s:\n",
    "        if isinstance(item, str):\n",
    "            order.append(item)\n",
    "            break\n",
    "\n",
    "connections = [list(perm) for perm in itertools.permutations([i for i in range(0, 17)], 2)]\n",
    "\n",
    "class NameEncoder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', device=None):\n",
    "        self.device = device\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, name_array):\n",
    "        x = self.model.encode(name_array, show_progress_bar=False,\n",
    "                              convert_to_tensor=True, device=self.device)\n",
    "        return x.cpu()\n",
    "\n",
    "\n",
    "def convert_keypoints_to_graph(key_points):\n",
    "    \"\"\"Transforms the keypoints in a more usable format\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    for i, kp in enumerate(key_points):\n",
    "        pos = kp[0]\n",
    "        name = order[i]\n",
    "        graph.add_node(node_for_adding=name,\n",
    "                       pos=(pos[0], -pos[1]))\n",
    "    for source, target in connections:\n",
    "        n1 = order[source]\n",
    "        n2 = order[target]\n",
    "        co1 = key_points[source][0]\n",
    "        co2 = key_points[target][0]\n",
    "        weight = math.dist(co1, co2)\n",
    "        graph.add_edge(n1, n2, weight=weight)\n",
    "    return graph\n",
    "        \n",
    "class PoseDataset(InMemoryDataset):\n",
    "    def __init__(self, raw_file_name, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        # the root argument should point to the directory where you have saved the data or want to save it\n",
    "        self.raw_file_name = raw_file_name\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [self.raw_file_name]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        target_file = self.raw_file_names[0]\n",
    "        file_name = target_file.split('/')[-1].split('.')[0]\n",
    "        filelist = [];\n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                if file_name in file and file.endswith('pt'):\n",
    "                    # json_file = os.path.join(root,file)\n",
    "                    filelist.append(file)\n",
    "        return filelist\n",
    "\n",
    "    @property\n",
    "    def num_classes(self):\n",
    "        return 2\n",
    "    \n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        name_encoder = NameEncoder()\n",
    "        for file_number, file in enumerate(self.raw_file_names):\n",
    "            file_name = file.split('/')[-1].split('.')[0]\n",
    "            df_data = pd.read_csv(file, chunksize=1000)\n",
    "            for chunk_index, df_chunk in enumerate(df_data):\n",
    "                data_list = []\n",
    "                for row_index, row in df_chunk.iterrows():\n",
    "                    kp = row.normalized_keypoints\n",
    "                    if isinstance(row.normalized_keypoints, str):\n",
    "                        kp = literal_eval(row.normalized_keypoints)\n",
    "                    graph = convert_keypoints_to_graph(kp)\n",
    "                    data = convert.from_networkx(graph)\n",
    "                    data.y = 1 if row.label == 'normal' else 0,\n",
    "                    xs = [name_encoder([node for node in graph.nodes()])]\n",
    "                    data.x = torch.cat(xs, dim=-1)\n",
    "                    # data = Data(\n",
    "                    #     x=x,\n",
    "                    #    edge_index=torch.from_numpy(np.array(connections)),\n",
    "                    #      edge_attr=torch.from_numpy(np.array([[item] for item in get_edge_weight(graph)])),\n",
    "                    #     y=1 if row.label == 'normal' else 0,\n",
    "                    #     pos=torch.from_numpy(positions ),\n",
    "                    # )\n",
    "                    data_list.append(data)\n",
    "                \n",
    "                if self.pre_filter is not None:\n",
    "                    data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "                \n",
    "                if self.pre_transform is not None:\n",
    "                    data_list = [self.pre_transform(data) for data in data_list]\n",
    "                self.save(data_list, f'./PyGod/data/UBnormal/processed/{file_name}_{chunk_index}.pt')\n",
    "                print(f\"Saved data to ./PyGod/data/UBnormal/processed/{file_name}_{chunk_index}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c0e0f-39ef-410f-a29e-fb8e1460dbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c28644-85e6-4119-b0ed-00e20262af24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b1a19946-1f10-42af-9a55-6fdac6ab14a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to ./PyGod/data/UBnormal/processed/testing_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PoseDataset('./PyGod/data/UBnormal/testing.csv', './PyGod/data/UBnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d0efe2f4-c60c-477d-9bb8-3258473e8849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to ./PyGod/data/UBnormal/processed/validation_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = PoseDataset('./PyGod/data/UBnormal/validation.csv', './PyGod/data/UBnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aef32062-084e-4728-a2f6-63ad4895578e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to ./PyGod/data/UBnormal/processed/training_0.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_1.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_2.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_3.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_4.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_5.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_6.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_7.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_8.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_9.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_10.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_11.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_12.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_13.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_14.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_15.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_16.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_17.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_18.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_19.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_20.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_21.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_22.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_23.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_24.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_25.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_26.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_27.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_28.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_29.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_30.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_31.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_32.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_33.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_34.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_35.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_36.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_37.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_38.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_39.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_40.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_41.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_42.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_43.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_44.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_45.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_46.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_47.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_48.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_49.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_50.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_51.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_52.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_53.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_54.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_55.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_56.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_57.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_58.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_59.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_60.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_61.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_62.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_63.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_64.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_65.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_66.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_67.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_68.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_69.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_70.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_71.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_72.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_73.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_74.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_75.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_76.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_77.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_78.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_79.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_80.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_81.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_82.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_83.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_84.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_85.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_86.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_87.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_88.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_89.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_90.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_91.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_92.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_93.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_94.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_95.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_96.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_97.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_98.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_99.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_100.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_101.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_102.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_103.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_104.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_105.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_106.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_107.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_108.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_109.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_110.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_111.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_112.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_113.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_114.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_115.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_116.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_117.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_118.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_119.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_120.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_121.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_122.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_123.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_124.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_125.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_126.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_127.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_128.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_129.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_130.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_131.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_132.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_133.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_134.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_135.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_136.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_137.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_138.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_139.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_140.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_141.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_142.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_143.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_144.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_145.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_146.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_147.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_148.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_149.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_150.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_151.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_152.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_153.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_154.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_155.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_156.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_157.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_158.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_159.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_160.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_161.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_162.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_163.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_164.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_165.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_166.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_167.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_168.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_169.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_170.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_171.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_172.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_173.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_174.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_175.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_176.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_177.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_178.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_179.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_180.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_181.pt\n",
      "Saved data to ./PyGod/data/UBnormal/processed/training_182.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "training_dataset = PoseDataset('./PyGod/data/UBnormal/training.csv', './PyGod/data/UBnormal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556a38e-1c2e-4d56-afd9-938a04410033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6dfdbe-b492-406b-8fa8-eb41a9c574dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77e5109c-ed03-4277-9a8d-48d96a77b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(training_dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, training_dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de91b7-ce51-4471-825a-7c934db28fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f77fc-20e9-46e2-875a-131d81bd0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To TEst:\n",
    "# DONE, AdONE, CoLA, CONAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a1c35-03ac-4e0a-a8d1-d48c3a3ff251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18ce8072-128a-410b-bb05-1802b30c97a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5229ca32-3078-4a1a-a915-8982b436a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.detector import DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7858b9-a297-4825-b376-7b147a928275",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DONE(device_map=\"auto\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab94d0-3d21-4eb5-8e8f-a8d0f65fb751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca80953-a6cf-4737-8c8d-39e20376b733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7d12072-8dc8-4fa4-9b72-223b42f4532f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/pygod/detector/base.py:461\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[0;34m(self, data, label)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgan:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_loss_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sampled_data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m    462\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m sampled_data\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    463\u001b[0m     node_idx \u001b[38;5;241m=\u001b[39m sampled_data\u001b[38;5;241m.\u001b[39mn_id\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/loader/node_loader.py:147\u001b[0m, in \u001b[0;36mNodeLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m input_data: NodeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[0;32m--> 147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:322\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_nodes\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_from_nodes\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m     inputs: NodeSamplerInput,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 322\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnode_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m==\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39mbidirectional:\n\u001b[1;32m    324\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto_bidirectional()\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:542\u001b[0m, in \u001b[0;36mnode_sample\u001b[0;34m(inputs, sample_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     seed \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnode\n\u001b[1;32m    540\u001b[0m     seed_time \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtime\n\u001b[0;32m--> 542\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m out\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m (inputs\u001b[38;5;241m.\u001b[39minput_id, inputs\u001b[38;5;241m.\u001b[39mtime)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:508\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m     num_sampled_nodes \u001b[38;5;241m=\u001b[39m num_sampled_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-sparse\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SamplerOutput(\n\u001b[1;32m    512\u001b[0m     node\u001b[38;5;241m=\u001b[39mnode,\n\u001b[1;32m    513\u001b[0m     row\u001b[38;5;241m=\u001b[39mrow,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m     num_sampled_edges\u001b[38;5;241m=\u001b[39mnum_sampled_edges,\n\u001b[1;32m    519\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "detector.fit(training_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32af004b-4910-4924-a479-4b9142b46351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages (from torch-sparse) (1.9.3)\n",
      "Requirement already satisfied: numpy<1.26.0,>=1.18.5 in /home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages (from scipy->torch-sparse) (1.23.3)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[79 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/cpp_extension.py:499: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.8\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.linux-x86_64-3.8/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m /home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/cpp_extension.py:418: UserWarning: The detected CUDA version (12.4) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "  \u001b[31m   \u001b[0m /home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/cpp_extension.py:428: UserWarning: There are no g++ version bounds defined for CUDA version 12.4\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._convert_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.8\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.8/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.8/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/ruben/miniconda3/envs/pose_graph_anomaly/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-rsaie31_/torch-sparse_5219d0659de54b2181358d4b8fb45819/third_party/parallel-hashmap -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/TH -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/THC -I/home/ruben/miniconda3/envs/pose_graph_anomaly/include/python3.8 -c csrc/convert.cpp -o build/temp.linux-x86_64-3.8/csrc/convert.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m cc1plus: warning: command-line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/ruben/miniconda3/envs/pose_graph_anomaly/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_PYTHON -Icsrc -I/tmp/pip-install-rsaie31_/torch-sparse_5219d0659de54b2181358d4b8fb45819/third_party/parallel-hashmap -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/TH -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/THC -I/home/ruben/miniconda3/envs/pose_graph_anomaly/include/python3.8 -c csrc/cpu/convert_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m cc1plus: warning: command-line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  \u001b[31m   \u001b[0m g++ -pthread -shared -B /home/ruben/miniconda3/envs/pose_graph_anomaly/compiler_compat -L/home/ruben/miniconda3/envs/pose_graph_anomaly/lib -Wl,-rpath=/home/ruben/miniconda3/envs/pose_graph_anomaly/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.8/csrc/convert.o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o -L/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/torch_sparse/_convert_cpu.so -s\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._convert_cuda' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-3.8/csrc/cuda\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/ruben/miniconda3/envs/pose_graph_anomaly/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-rsaie31_/torch-sparse_5219d0659de54b2181358d4b8fb45819/third_party/parallel-hashmap -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/TH -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/THC -I/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.4/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/include/python3.8 -c csrc/convert.cpp -o build/temp.linux-x86_64-3.8/csrc/convert.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m cc1plus: warning: command-line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /home/ruben/miniconda3/envs/pose_graph_anomaly/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-rsaie31_/torch-sparse_5219d0659de54b2181358d4b8fb45819/third_party/parallel-hashmap -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/TH -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/THC -I/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.4/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/include/python3.8 -c csrc/cpu/convert_cpu.cpp -o build/temp.linux-x86_64-3.8/csrc/cpu/convert_cpu.o -O3 -Wno-sign-compare -DAT_PARALLEL_OPENMP -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
      "  \u001b[31m   \u001b[0m cc1plus: warning: command-line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
      "  \u001b[31m   \u001b[0m /home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation.\n",
      "  \u001b[31m   \u001b[0m If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m /mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.4/bin/nvcc -DWITH_PYTHON -DWITH_CUDA -Icsrc -I/tmp/pip-install-rsaie31_/torch-sparse_5219d0659de54b2181358d4b8fb45819/third_party/parallel-hashmap -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/TH -I/home/ruben/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch/include/THC -I/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.4/include -I/home/ruben/miniconda3/envs/pose_graph_anomaly/include/python3.8 -c csrc/cuda/convert_cuda.cu -o build/temp.linux-x86_64-3.8/csrc/cuda/convert_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 --expt-relaxed-constexpr -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=_convert_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
      "  \u001b[31m   \u001b[0m nvcc fatal   : Cannot find compiler 'cl.exe' in PATH\n",
      "  \u001b[31m   \u001b[0m error: command '/mnt/c/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v12.4/bin/nvcc' failed with exit status 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-sparse\n",
      "\u001b[31mERROR: Could not build wheels for torch-sparse, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch-sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b005bcf0-b323-4af0-ad95-ffd7748e12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DOMINANT(hid_dim=64, num_layers=4, epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57cd1f93-007d-4f2d-bfb1-35ce4ce86572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected a 'Data', 'HeteroData', or a tuple of 'FeatureStore' and 'GraphStore' (got '<class '__main__.PoseDataset'>')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/pygod/detector/base.py:435\u001b[0m, in \u001b[0;36mDeepDetector.fit\u001b[0;34m(self, data, label)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 435\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_neigh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile_model:\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/loader/neighbor_loader.py:229\u001b[0m, in \u001b[0;36mNeighborLoader.__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, input_time, replace, subgraph_type, disjoint, temporal_strategy, time_attr, weight_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, directed, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived conflicting \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m arguments: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_attr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neighbor_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     neighbor_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mNeighborSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubgraph_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgraph_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemporal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemporal_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    244\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    245\u001b[0m     node_sampler\u001b[38;5;241m=\u001b[39mneighbor_sampler,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    252\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py:66\u001b[0m, in \u001b[0;36mNeighborSampler.__init__\u001b[0;34m(self, data, num_neighbors, subgraph_type, replace, disjoint, temporal_strategy, time_attr, weight_attr, is_sorted, share_memory, directed)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_PYG_LIB \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinux\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m subgraph_type \u001b[38;5;241m!=\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39minduced):\n\u001b[1;32m     61\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m without a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m installation is deprecated and will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremoved soon. Please install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerated neighborhood sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m=\u001b[39m \u001b[43mDataType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m==\u001b[39m DataType\u001b[38;5;241m.\u001b[39mhomogeneous:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_nodes\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/sampler/base.py:36\u001b[0m, in \u001b[0;36mDataType.from_data\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     32\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m0\u001b[39m], FeatureStore)\n\u001b[1;32m     33\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;241m1\u001b[39m], GraphStore)):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mremote\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeteroData\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or a tuple of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatureStore\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGraphStore\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected a 'Data', 'HeteroData', or a tuple of 'FeatureStore' and 'GraphStore' (got '<class '__main__.PoseDataset'>')"
     ]
    }
   ],
   "source": [
    "detector.fit(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e73b9-edc0-4cb3-abc3-9ae27effa794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850351a-adf5-44dc-86fe-17c19cd133e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f0982a-27df-456d-9770-309f8cdeee9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2c5a1-7a20-4a53-9696-c0e1518c5440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dabfe8f6-8959-43b0-8788-045b107ef619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'train_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[0;32m---> 10\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out[\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_mask\u001b[49m], data\u001b[38;5;241m.\u001b[39my[data\u001b[38;5;241m.\u001b[39mtrain_mask])\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/data/data.py:559\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pose_graph_anomaly/lib/python3.8/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'train_mask'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = training_dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4bca658-7de2-4919-a7e2-fdb07b59d6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 272], pos=[17, 2], weight=[272], y=[1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bcce55-fe22-418b-b601-870af241fe74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bcb04-e9db-4631-891b-bb0a4bb910a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29533b-0cf6-40da-abc0-f4eaf6533c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569f7c2-47e8-42b0-9702-4988fea60156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39042cb1-411b-46be-b18a-ae2dc67b6eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9f11c-c3e2-450c-934d-8705914ab81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819ac37-3784-4979-ae30-da3fff49293d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
